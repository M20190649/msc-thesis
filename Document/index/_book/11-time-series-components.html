<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 11 2.3 Time series components | Spatio-Temporal Forecasts for Bike Availability in Dockless Bike Sharing Systems</title>
  <meta name="description" content="Chapter 11 2.3 Time series components | Spatio-Temporal Forecasts for Bike Availability in Dockless Bike Sharing Systems">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 11 2.3 Time series components | Spatio-Temporal Forecasts for Bike Availability in Dockless Bike Sharing Systems" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 2.3 Time series components | Spatio-Temporal Forecasts for Bike Availability in Dockless Bike Sharing Systems" />
  
  
  

<meta name="author" content="Lucas van der Meer">


<meta name="date" content="2019-02-25">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="10-time-series-characteristics.html">
<link rel="next" href="12-time-series-forecasting.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"></a></li>
<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="1-introduction-1.html"><a href="1-introduction-1.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="2-context.html"><a href="2-context.html"><i class="fa fa-check"></i><b>2</b> 1.1 Context</a></li>
<li class="chapter" data-level="3" data-path="3-objective.html"><a href="3-objective.html"><i class="fa fa-check"></i><b>3</b> 1.2 Objective</a></li>
<li class="chapter" data-level="4" data-path="4-related-work.html"><a href="4-related-work.html"><i class="fa fa-check"></i><b>4</b> 1.3 Related work</a><ul>
<li class="chapter" data-level="4.1" data-path="4-related-work.html"><a href="4-related-work.html#forecasting-in-station-based-systems"><i class="fa fa-check"></i><b>4.1</b> 1.3.1 Forecasting in station-based systems</a></li>
<li class="chapter" data-level="4.2" data-path="4-related-work.html"><a href="4-related-work.html#forecasting-in-dockless-systems"><i class="fa fa-check"></i><b>4.2</b> 1.3.2 Forecasting in dockless systems</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-approach.html"><a href="5-approach.html"><i class="fa fa-check"></i><b>5</b> 1.4 Approach</a></li>
<li class="chapter" data-level="6" data-path="6-outline.html"><a href="6-outline.html"><i class="fa fa-check"></i><b>6</b> 1.5 Outline</a></li>
<li class="chapter" data-level="7" data-path="7-references.html"><a href="7-references.html"><i class="fa fa-check"></i><b>7</b> References</a></li>
<li class="chapter" data-level="8" data-path="8-theoretical-background.html"><a href="8-theoretical-background.html"><i class="fa fa-check"></i><b>8</b> Theoretical background</a></li>
<li class="chapter" data-level="9" data-path="9-time-series-definition.html"><a href="9-time-series-definition.html"><i class="fa fa-check"></i><b>9</b> 2.1 Time series definition</a></li>
<li class="chapter" data-level="10" data-path="10-time-series-characteristics.html"><a href="10-time-series-characteristics.html"><i class="fa fa-check"></i><b>10</b> 2.2 Time series characteristics</a><ul>
<li class="chapter" data-level="10.1" data-path="10-time-series-characteristics.html"><a href="10-time-series-characteristics.html#autocorrelation"><i class="fa fa-check"></i><b>10.1</b> 2.2.1 Autocorrelation</a></li>
<li class="chapter" data-level="10.2" data-path="10-time-series-characteristics.html"><a href="10-time-series-characteristics.html#stationarity"><i class="fa fa-check"></i><b>10.2</b> 2.2.2 Stationarity</a></li>
<li class="chapter" data-level="10.3" data-path="10-time-series-characteristics.html"><a href="10-time-series-characteristics.html#spectral-entropy"><i class="fa fa-check"></i><b>10.3</b> 2.2.3 Spectral entropy</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-time-series-components.html"><a href="11-time-series-components.html"><i class="fa fa-check"></i><b>11</b> 2.3 Time series components</a><ul>
<li class="chapter" data-level="11.1" data-path="11-time-series-components.html"><a href="11-time-series-components.html#definitions"><i class="fa fa-check"></i><b>11.1</b> 2.3.1 Definitions</a></li>
<li class="chapter" data-level="11.2" data-path="11-time-series-components.html"><a href="11-time-series-components.html#classical-decomposition"><i class="fa fa-check"></i><b>11.2</b> 2.3.2 Classical decomposition</a></li>
<li class="chapter" data-level="11.3" data-path="11-time-series-components.html"><a href="11-time-series-components.html#stl-decomposition"><i class="fa fa-check"></i><b>11.3</b> 2.3.3 STL decomposition</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-time-series-forecasting.html"><a href="12-time-series-forecasting.html"><i class="fa fa-check"></i><b>12</b> 2.4 Time series forecasting</a><ul>
<li class="chapter" data-level="12.1" data-path="12-time-series-forecasting.html"><a href="12-time-series-forecasting.html#forecasting-models"><i class="fa fa-check"></i><b>12.1</b> 2.4.1 Forecasting models</a></li>
<li class="chapter" data-level="12.2" data-path="12-time-series-forecasting.html"><a href="12-time-series-forecasting.html#arima"><i class="fa fa-check"></i><b>12.2</b> 2.4.2 ARIMA</a><ul>
<li class="chapter" data-level="12.2.1" data-path="12-time-series-forecasting.html"><a href="12-time-series-forecasting.html#structure"><i class="fa fa-check"></i><b>12.2.1</b> 2.4.2.1 Structure</a></li>
<li class="chapter" data-level="12.2.2" data-path="12-time-series-forecasting.html"><a href="12-time-series-forecasting.html#model-selection"><i class="fa fa-check"></i><b>12.2.2</b> 2.4.2.2 Model selection</a></li>
<li class="chapter" data-level="12.2.3" data-path="12-time-series-forecasting.html"><a href="12-time-series-forecasting.html#parameter-estimation"><i class="fa fa-check"></i><b>12.2.3</b> 2.4.2.3 Parameter estimation</a></li>
<li class="chapter" data-level="12.2.4" data-path="12-time-series-forecasting.html"><a href="12-time-series-forecasting.html#model-checking"><i class="fa fa-check"></i><b>12.2.4</b> 2.4.2.4 Model checking</a></li>
<li class="chapter" data-level="12.2.5" data-path="12-time-series-forecasting.html"><a href="12-time-series-forecasting.html#forecasting"><i class="fa fa-check"></i><b>12.2.5</b> 2.4.2.5 Forecasting</a></li>
<li class="chapter" data-level="12.2.6" data-path="12-time-series-forecasting.html"><a href="12-time-series-forecasting.html#accuracy-evaluation"><i class="fa fa-check"></i><b>12.2.6</b> 2.4.2.6 Accuracy evaluation</a></li>
<li class="chapter" data-level="12.2.7" data-path="12-time-series-forecasting.html"><a href="12-time-series-forecasting.html#transformations"><i class="fa fa-check"></i><b>12.2.7</b> 2.4.2.7 Transformations</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="12-time-series-forecasting.html"><a href="12-time-series-forecasting.html#naive-forecasts"><i class="fa fa-check"></i><b>12.3</b> 2.4.3 Na√Øve forecasts</a></li>
<li class="chapter" data-level="12.4" data-path="12-time-series-forecasting.html"><a href="12-time-series-forecasting.html#seasonal-forecasts"><i class="fa fa-check"></i><b>12.4</b> 2.4.4 Seasonal forecasts</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="13-time-series-clustering.html"><a href="13-time-series-clustering.html"><i class="fa fa-check"></i><b>13</b> 2.5 Time series clustering</a><ul>
<li class="chapter" data-level="13.1" data-path="13-time-series-clustering.html"><a href="13-time-series-clustering.html#dissimilarity-measures"><i class="fa fa-check"></i><b>13.1</b> 2.5.1 Dissimilarity measures</a></li>
<li class="chapter" data-level="13.2" data-path="13-time-series-clustering.html"><a href="13-time-series-clustering.html#hierarchical-clustering"><i class="fa fa-check"></i><b>13.2</b> 2.5.2 Hierarchical clustering</a></li>
<li class="chapter" data-level="13.3" data-path="13-time-series-clustering.html"><a href="13-time-series-clustering.html#spatial-time-series-clustering"><i class="fa fa-check"></i><b>13.3</b> 2.5.3 Spatial time series clustering</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="14-references-1.html"><a href="14-references-1.html"><i class="fa fa-check"></i><b>14</b> References</a></li>
<li class="chapter" data-level="15" data-path="15-system-architecture.html"><a href="15-system-architecture.html"><i class="fa fa-check"></i><b>15</b> System architecture</a></li>
<li class="chapter" data-level="16" data-path="16-overall-design.html"><a href="16-overall-design.html"><i class="fa fa-check"></i><b>16</b> 3.1 Overall design</a></li>
<li class="chapter" data-level="17" data-path="17-software.html"><a href="17-software.html"><i class="fa fa-check"></i><b>17</b> 3.2 Software</a></li>
<li class="chapter" data-level="18" data-path="18-system-area.html"><a href="18-system-area.html"><i class="fa fa-check"></i><b>18</b> 3.3 System area</a></li>
<li class="chapter" data-level="19" data-path="19-database.html"><a href="19-database.html"><i class="fa fa-check"></i><b>19</b> 3.4 Database</a><ul>
<li class="chapter" data-level="19.1" data-path="19-database.html"><a href="19-database.html#distance-data"><i class="fa fa-check"></i><b>19.1</b> 3.4.1 Distance data</a></li>
<li class="chapter" data-level="19.2" data-path="19-database.html"><a href="19-database.html#usage-data"><i class="fa fa-check"></i><b>19.2</b> 3.4.2 Usage data</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="20-forecast-request.html"><a href="20-forecast-request.html"><i class="fa fa-check"></i><b>20</b> 3.5 Forecast request</a></li>
<li class="chapter" data-level="21" data-path="21-cluster-loop.html"><a href="21-cluster-loop.html"><i class="fa fa-check"></i><b>21</b> 3.6 Cluster loop</a></li>
<li class="chapter" data-level="22" data-path="22-model-loop.html"><a href="22-model-loop.html"><i class="fa fa-check"></i><b>22</b> 3.7 Model loop</a></li>
<li class="chapter" data-level="23" data-path="23-forecast-loop.html"><a href="23-forecast-loop.html"><i class="fa fa-check"></i><b>23</b> 3.8 Forecast loop</a></li>
<li class="chapter" data-level="24" data-path="24-references-2.html"><a href="24-references-2.html"><i class="fa fa-check"></i><b>24</b> References</a></li>
<li class="chapter" data-level="25" data-path="25-data-and-experimental-design.html"><a href="25-data-and-experimental-design.html"><i class="fa fa-check"></i><b>25</b> Data and experimental design</a></li>
<li class="chapter" data-level="26" data-path="26-data-source.html"><a href="26-data-source.html"><i class="fa fa-check"></i><b>26</b> 4.1 Data source</a></li>
<li class="chapter" data-level="27" data-path="27-data-retrieval.html"><a href="27-data-retrieval.html"><i class="fa fa-check"></i><b>27</b> 4.2 Data retrieval</a><ul>
<li class="chapter" data-level="27.1" data-path="27-data-retrieval.html"><a href="27-data-retrieval.html#distance-data-1"><i class="fa fa-check"></i><b>27.1</b> 4.2.1 Distance data</a></li>
<li class="chapter" data-level="27.2" data-path="27-data-retrieval.html"><a href="27-data-retrieval.html#usage-data-1"><i class="fa fa-check"></i><b>27.2</b> 4.2.2 Usage data</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="28-experimental-design.html"><a href="28-experimental-design.html"><i class="fa fa-check"></i><b>28</b> 4.3 Experimental design</a><ul>
<li class="chapter" data-level="28.1" data-path="28-experimental-design.html"><a href="28-experimental-design.html#training-and-test-periods"><i class="fa fa-check"></i><b>28.1</b> 4.3.1 Training and test periods</a></li>
<li class="chapter" data-level="28.2" data-path="28-experimental-design.html"><a href="28-experimental-design.html#additional-software"><i class="fa fa-check"></i><b>28.2</b> 4.3.3 Additional software</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="29-references-3.html"><a href="29-references-3.html"><i class="fa fa-check"></i><b>29</b> References</a></li>
<li class="chapter" data-level="30" data-path="30-results-and-discussion.html"><a href="30-results-and-discussion.html"><i class="fa fa-check"></i><b>30</b> Results and discussion</a></li>
<li class="chapter" data-level="31" data-path="31-clustering.html"><a href="31-clustering.html"><i class="fa fa-check"></i><b>31</b> 5.1 Clustering</a></li>
<li class="chapter" data-level="32" data-path="32-model-building.html"><a href="32-model-building.html"><i class="fa fa-check"></i><b>32</b> 5.2 Model building</a></li>
<li class="chapter" data-level="33" data-path="33-forecasting-1.html"><a href="33-forecasting-1.html"><i class="fa fa-check"></i><b>33</b> 5.3 Forecasting</a></li>
<li class="chapter" data-level="34" data-path="34-limitations-recommendations.html"><a href="34-limitations-recommendations.html"><i class="fa fa-check"></i><b>34</b> 5.4 Limitations &amp; Recommendations</a><ul>
<li class="chapter" data-level="34.1" data-path="34-limitations-recommendations.html"><a href="34-limitations-recommendations.html#limits-of-forecastability"><i class="fa fa-check"></i><b>34.1</b> 5.4.1 Limits of forecastability</a></li>
<li class="chapter" data-level="34.2" data-path="34-limitations-recommendations.html"><a href="34-limitations-recommendations.html#exogeneous-variables"><i class="fa fa-check"></i><b>34.2</b> 5.4.2 Exogeneous variables</a></li>
<li class="chapter" data-level="34.3" data-path="34-limitations-recommendations.html"><a href="34-limitations-recommendations.html#non-normal-distributions"><i class="fa fa-check"></i><b>34.3</b> 5.4.3 Non-normal distributions</a></li>
</ul></li>
<li class="chapter" data-level="35" data-path="35-references-4.html"><a href="35-references-4.html"><i class="fa fa-check"></i><b>35</b> References</a></li>
<li class="chapter" data-level="36" data-path="36-conclusion.html"><a href="36-conclusion.html"><i class="fa fa-check"></i><b>36</b> Conclusion</a></li>
<li class="chapter" data-level="" data-path="references-5.html"><a href="references-5.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Spatio-Temporal Forecasts for Bike Availability in Dockless Bike Sharing Systems</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="time-series-components" class="section level1">
<h1><span class="header-section-number">Chapter 11</span> 2.3 Time series components</h1>
<div id="definitions" class="section level2">
<h2><span class="header-section-number">11.1</span> 2.3.1 Definitions</h2>
<p>A time series can consist of various underlying patterns. Each of those patterns is considered a distinct component of the time series, with its own properties and behaviour. Splitting a time series into its components is known as <em>time series decomposition</em>. It enables a separate analysis of all the components, which helps to better understand the dynamics of a time series, but can also be useful in forecasting, as is showed later in this chapter.</p>
<p><span class="citation">Hyndman &amp; Athanasopoulos (2018)</span> define three main components of a time series: a trend-cycle component, a seasonal component and a remainder component. For simplicity, the trend-cycle component is usually called just the trend component, which is done in this thesis as well.</p>
<p><strong>Definition 4</strong> The <em>trend component</em> is the combination of the trend and cyclical pattern of a time series. A trend exists when there is a long-term, not necessarily linear, increase or decrease in the data. A cyclical pattern occurs when the data exhibit rises and falls that are not of a fixed frequency. <span class="math inline">\(\blacksquare\)</span></p>
<p><strong>Definition 5</strong> The <em>seasonal component</em> contains the seasonal pattern of a time series. A seasonal pattern occurs when a time series is affected by seasonal factors such as the time of the year or the day of the week. Seasonality is always of a fixed and known frequency. <span class="math inline">\(\blacksquare\)</span></p>
<p><strong>Definition 6</strong> The <em>remainder component</em> is the remaining variation in a time series after the trend and seasonal components are removed. <span class="math inline">\(\blacksquare\)</span></p>
<p>There exist several different methods for the decomposition of a time series. Most of them are based on the classical decomposition method, which is discussed in the next section. A more sophisticated approach is known as STL, and is covered in section 2.2.2.3.</p>
</div>
<div id="classical-decomposition" class="section level2">
<h2><span class="header-section-number">11.2</span> 2.3.2 Classical decomposition</h2>
<p>The oldest and simplest method for the decomposition of a time series is referred to as classical decomposition by <span class="citation">Hyndman &amp; Athanasopoulos (2018)</span>. They present a stepwise approach for the use of the method, which is summarized in this section. Classical decomposition can be applied in two different forms. In the additive form, a time series is assumed to be the sum of its components, as shown in Equation 2.</p>
<p><span class="math display">\[ y_{t} = T_{t} + S_{t} + R_{t} \]</span></p>
<p>In the multiplicative form, a time series is assumed to be the product of its components, as shown in Equation 3.</p>
<p><span class="math display">\[ y_{t} = T_{t} \times S_{t} \times R_{t} \]</span></p>
<p>Where, for both Equation 2 and Equation 3, <span class="math inline">\(y_{t}\)</span> is the data, <span class="math inline">\(T_{t}\)</span> is the trend component, <span class="math inline">\(S_{t}\)</span> is the seasonal component and <span class="math inline">\(R_{t}\)</span> is the remainder component.</p>
<p>Additive decomposition is the appropriate form when the amplitude of the variation around the trend is relatively constant. On the other hand, when the amplitude of the variation around the trend changes with the level of the trend, multiplicative decomposition should be used.</p>
<p>In both the additive and multiplicative form of classical decomposition, the first step is to estimate the trend component. This is done by smoothing the data with a symmetric moving average filter of order <span class="math inline">\(m\)</span>, where <span class="math inline">\(m\)</span> is a non-negative integer. That is, the estimate of the trend component at time <span class="math inline">\(t\)</span> is the average of all the data values within a window of <span class="math inline">\(m\)</span> time periods centered at <span class="math inline">\(t\)</span>, as shown in Equation 4. Usually, <span class="math inline">\(m\)</span> is set to be equal to the seasonal period of the time series, which, in turn, is the number of observations per seasonal cycle. For example, when working with daily data that show a weekly seasonal pattern, the seasonal period is 7.</p>
<p><span class="math display">\[ \hat{T}_{t} = \frac{1}{m}\sum_{j=-k}^{k}y_{t+j} \]</span></p>
<p>Where <span class="math inline">\(k = (m-1)/2\)</span>. The detrended time series data are then calculated by removing the estimated trend component from the original data. In the case of additive decomposition by subtraction, <span class="math inline">\(y_{t} - \hat{T}_{t}\)</span>, and in the case of multiplicative decomposition by division, <span class="math inline">\(y_{t}/\hat{T}_{t}\)</span>.</p>
<p>The seasonal component is estimated by averaging the detrended data values per season, as shown in Equation 5. Using again the example of daily data with a weekly seasonal pattern, that would mean that the estimated seasonal component for a specific Monday is the average value of all Monday observations in the data set, the estimated seasonal component for a specific Tuesday is the average value of all Tuesday observations in the data set, and so on.</p>
<p><span class="math display">\[ \hat{S}_{t} = \frac{1}{n_{t}}\sum_{i=1}^{n_{t}}(\omega_{t})_{i} \]</span></p>
<p>Where <span class="math inline">\(\omega_{t}\)</span> is a vector containing all the detrended values belonging to the same season as <span class="math inline">\(y_{t}\)</span>, and <span class="math inline">\(n_{t}\)</span> is the length of <span class="math inline">\(\omega_{t}\)</span>. Usually, the estimated seasonal component values for each season are adjusted such that they add up to 0 in the case of additive decomposition and 1 in the case of multiplicative decomposition.</p>
<p>Finally, the remainder component is estimated by removing both the estimated trend component and the estimated seasonal component from the original time series. For additive decomposition, this is done by applying Equation 6.</p>
<p><span class="math display">\[ \hat{R}_{t} = y_{t} - \hat{T}_{t} - \hat{S}_{t} \]</span></p>
<p>For multiplicative decomposition, Equation 7 is used.</p>
<p><span class="math display">\[ \hat{R}_{t} = \frac{y_{t}}{\hat{T}_{t}\hat{S}_{t}} \]</span></p>
<p>Classical decomposition is generally praised for its simplicity, but has several disadvantages compared to some of the more modern decomposition methods <span class="citation">(Hyndman &amp; Athanasopoulos, 2018)</span>. As a consequence of the use of a symmetric moving average filter, there are no trend component estimates available for the first few and last few observations of the time series. Therefore, also the remainder component estimate lacks these values. This is mainly problematic when forecasting, as is showed later in this chapter. Furthermore, the seasonal component stays constant over all the seasonal cycles, and cannot capture slight changes over time. Especially when working with longer time series, this may be an inappropriate representation of the truth. Finally, classical decomposition is not robust to extreme values in the data.</p>
</div>
<div id="stl-decomposition" class="section level2">
<h2><span class="header-section-number">11.3</span> 2.3.3 STL decomposition</h2>
<p>A widely used method that is based on classical decomposition, but deals with many of the limitations mentioned above, is known as STL. It stands for <em>A Seasonal-Trend decomposition procedure based on Loess</em>, and was developed by <span class="citation">R. B. Cleveland, Cleveland, McRae, &amp; Terpenning (1990)</span>. In this section, their methodology is summarized. STL estimates all three components for every observation in a time series, and can also handle missing values in the data. Both the trend and seasonal component are robust and not distorted by extreme values. Furthermore, the seasonal component is not fixed, but can vary slightly over time.</p>
<p>As its name already implies, STL is based on loess, also known as locally-weighted regression. Loess was developed by <span class="citation">Cleveland &amp; Devlin (1988)</span>, and is a non-parametric regression technique, often used for smoothing, that fits weighted least squares regression curves to local subsets of a data set. Joining them together forms the loess regression curve <span class="math inline">\(\hat{g}(x)\)</span>. More specifically, for each value of <span class="math inline">\(x\)</span>, <span class="math inline">\(\hat{g}(x)\)</span> is computed in the following way. First, a positive integer <span class="math inline">\(q\)</span> is chosen, which defines the neighbourhood width. That is, the <span class="math inline">\(q\)</span> observations that are closest to <span class="math inline">\(x\)</span> are selected as neighbours of <span class="math inline">\(x\)</span>. Each of these observations is given a weight based on its distance to x, in a way that the closest observations get the highest weight. Let <span class="math inline">\(W\)</span> be the tricube weight function as defined in Equation 8.</p>
<p><span class="math display">\[
W(u) = 
    \begin{cases}
      (1 - u^{3})^{3} &amp;\quad 0 \leq u &lt; 1\\
      0 &amp;\quad u \geq 1\\
    \end{cases}
\]</span></p>
<p>Then, the neighbourhood weight for each observation <span class="math inline">\(x_{i}\)</span> is calculated with Equation 9.</p>
<p><span class="math display">\[ \upsilon_{i} = W\Bigg(\frac{|x_{i} - x|}{\lambda_{q}(x)}\Bigg) \]</span></p>
<p>Where <span class="math inline">\(\lambda_{q}(x)\)</span> is the distance of the <span class="math inline">\(q\)</span>th farthest observation from <span class="math inline">\(x\)</span>. Then, <span class="math inline">\(\hat{g}(x)\)</span> is calculated by fitting a polynomial regression of degree <span class="math inline">\(d\)</span> to x, using weighted least squares with the neighbourhood weights <span class="math inline">\(\upsilon_{i}\)</span>. Usually, <span class="math inline">\(d\)</span> is either <span class="math inline">\(1\)</span> or <span class="math inline">\(2\)</span>, corresponding respectively to a locally-linear regression and a locally-quadratic regression. Since the loess regression curve is smooth, there is no need to compute <span class="math inline">\(\hat{g}(x)\)</span> at all possible values of <span class="math inline">\(x\)</span>. In general, the computation of <span class="math inline">\(\hat{g}(x)\)</span> as described above is only performed at a finite set of locations, and interpolated elsewhere.</p>
<p>STL uses loess for several smoothing operations, that, when performed on a time series, lead to estimations of the trend, seasonal and remainder components of the data. The method is build up of two loops: an inner loop nested inside an outer loop. In the inner loop, the estimates of the seasonal and trend component are updated once, in a stepwise manner, which is described below.</p>
<p><strong>Step 1.</strong> The inner loop starts with computing the detrended time series data <span class="math inline">\(y_{t} - \hat{T}_{t}\)</span> from the original time series data <span class="math inline">\(y_{t}\)</span>. In the initial pass through the inner loop, there is no estimation of <span class="math inline">\(T_{t}\)</span> yet, and <span class="math inline">\(\hat{T}_{t}\)</span> is set equivalent to <span class="math inline">\(0\)</span>. That is, it is assumed there is no trend at all. This may be a rather poor estimate, but inside the loop, it will soon be updated to something more reasonable. In all successive passes through the loop, the estimated trend component that resulted from the previous loop is used.</p>
<p><strong>Step 2.</strong> In the second step, the detrended time series is split up into subsets, with each subset containing all the data belonging to one specific season. That is, there will be <span class="math inline">\(n_{p}\)</span> different subsets, where <span class="math inline">\(n_{p}\)</span> is the number of observations per seasonal cycle. Each of those subsets is smoothed by loess, with <span class="math inline">\(q = n_{s}\)</span> and <span class="math inline">\(d = 1\)</span>. <span class="math inline">\(n_{s}\)</span> is referred to as the seasonal smoothing parameter and its value must be chosen by the analyst. It basically determines how much the seasonal component is allowed to change over time. High values of <span class="math inline">\(n_{s}\)</span> allow little variation, while low values can lead to overfitting. The smoothed values of all the subsets are then binded back together into a temporary seasonal component <span class="math inline">\(C_{t}\)</span>. Each end of <span class="math inline">\(C_{t}\)</span> is extended <span class="math inline">\(n_{p}\)</span> positions, such that <span class="math inline">\(C_{t}\)</span> has <span class="math inline">\(2 \times n_{p}\)</span> observations more than the original time series.</p>
<p><strong>Step 3.</strong> In the third step, any trend that may have contaminated <span class="math inline">\(C_{t}\)</span> is identified. This is done by applying a sequence of smoothers, called a low-pass filter, to <span class="math inline">\(C_{t}\)</span>. It starts with a moving average of length <span class="math inline">\(n_{p}\)</span>, followed by another moving average of length <span class="math inline">\(n_{p}\)</span>, followed by a moving average of length 3, followed by a loess smoothing with <span class="math inline">\(q = n_{l}\)</span> and <span class="math inline">\(d = 1\)</span>. Just as earlier with <span class="math inline">\(n_{s}\)</span>, the low-pass filter smoothing parameter <span class="math inline">\(n_{l}\)</span> should be chosen by the analyst. The output of the third step is called <span class="math inline">\(L_{t}\)</span>. Since moving averages are used, the first <span class="math inline">\(n_{p}\)</span> observations and the last <span class="math inline">\(n_{p}\)</span> observations of <span class="math inline">\(C_{t}\)</span> will not have a smoothed value in <span class="math inline">\(L_{t}\)</span>. However, this was already accounted for by extending <span class="math inline">\(C_{t}\)</span> in step 2. That is, <span class="math inline">\(L_{t}\)</span> is again of the same length as the original time series.</p>
<p><strong>Step 4.</strong> In the fourth step, the seasonal component is estimated by detrending the temporary seasonal component. That is, <span class="math inline">\(\hat{S}_{t} = C_{t} - L_{t}\)</span>.</p>
<p><strong>Step 5.</strong> In the fifth step, the deseasonalized time series data <span class="math inline">\(y_{t} - \hat{S}_{t}\)</span> are computed from the original time series data <span class="math inline">\(y_{t}\)</span>.</p>
<p><strong>Step 6.</strong> In the sixth and last step of the inner loop, the estimation of the trend component, <span class="math inline">\(\hat{T}_{t}\)</span>, is calculated by loess smoothing the deseasonalized time series with <span class="math inline">\(q = n_{t}\)</span> and <span class="math inline">\(d = 1\)</span>. The trend smoothing parameter <span class="math inline">\(n_{t}\)</span> should be chosen by the analyst.</p>
<p>The outer loop of STL starts with <span class="math inline">\(n_{i}\)</span> iterations of the inner loop. The estimations of the trend and seasonal components that follow from the passes through the inner loop, are used to estimate the remainder component with Equation 10.</p>
<p><span class="math display">\[ \hat{R}_{t} = y_{t} - \hat{T}_{t} - \hat{S}_{t} \]</span></p>
<p>For each observation in the time series, a robustness weight is calculated. This weight reflects how extreme the value of the remainder component of that observation is, in a way that a very extreme value is given a very low, or even zero, weight. Let <span class="math inline">\(B\)</span> be the bisquare weight function as defined in Equation 11.</p>
<p><span class="math display">\[
B(u) = 
    \begin{cases}
      (1 - u^{2})^{2} &amp;\quad 0 \leq u &lt; 1\\
      0 &amp;\quad u \geq 1\\
    \end{cases}
\]</span></p>
<p>Then, the robustness weight at time point <span class="math inline">\(t\)</span> is calculated with Equation 12.</p>
<p><span class="math display">\[ \rho_{t} = B\Bigg(\frac{|R_{t}|}{6median(|R_{t}|)}\Bigg) \]</span></p>
<p>After the first pass of the outer loop, the next iteration starts again with <span class="math inline">\(n_{i}\)</span> passes through the inner loop. However, in the loess smoothing in step 2 and step 6, each neighbourhood weight <span class="math inline">\(\upsilon_{t}\)</span> is now multiplied by its corresponding robustness weight <span class="math inline">\(\rho_{t}\)</span>, such that extreme values have less influence on the estimates of the trend and seasonal components. Also, the estimated trend component that resulted from the last inner loop in the previous outer loop, is now used as first value of <span class="math inline">\(\hat{T}_{t}\)</span>, rather than <span class="math inline">\(0\)</span>. In total, the outer loop is carried out <span class="math inline">\(n_{o}\)</span> times.</p>
<p>STL is designed for additive decomposition. However, a multiplicative version can be obtained by first log transforming the data, and finally back-transforming the components. This is based on the logarithm product rule, which states that <span class="math inline">\(log(a) + log(b)\)</span> is equivalent to <span class="math inline">\(log(a \times b)\)</span> <span class="citation">(Hyndman &amp; Athanasopoulos, 2018)</span>.</p>
<p>The complete methodology of STL as described above is summarized in Figure 1.</p>
<div class="figure" style="text-align: center"><span id="fig:stl"></span>
<img src="Figures/STL.png" alt="Summary of the STL methodology" width="\textwidth" />
<p class="caption">
Figure 11.1: Summary of the STL methodology
</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="10-time-series-characteristics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="12-time-series-forecasting.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": [["thesis.pdf", "PDF"], ["thesis.epub", "EPUB"], ["thesis.docx", "Word"]],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
